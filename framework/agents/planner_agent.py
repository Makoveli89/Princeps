"""
PlannerAgent - High-Level Strategic Planner with Council-of-Experts

This module implements the PlannerAgent, responsible for breaking down complex
tasks and formulating strategies by consulting multiple expert LLMs.

Strategic Intent:
The PlannerAgent acts as a "meta-reasoner" that leverages collective intelligence
from multiple LLMs to produce more reliable and well-rounded plans. When given
a goal or complex query, it:
1. Retrieves relevant context from the Brain's knowledge base
2. Formulates planning prompts for the council of LLMs
3. Queries multiple models in parallel to gather proposed solutions
4. Consolidates responses using ensemble decision logic
5. Outputs a structured plan for the Executor to carry out

Integration with Brain Layer:
- All runs are logged to agent_runs table via BrainLogger
- Can retrieve relevant past tasks via RetrieverAgent
- Can fetch domain knowledge from knowledge_nodes
- All operations remain tenant-scoped
- Novel strategies can be distilled into knowledge atoms

Adapted from patterns in:
- reinforcement_learning.py: Action scoring and selection
- ab_testing.py: Comparing variants and outcomes
- multi_llm_client.py: Council pattern for response comparison
- base_agent.py: Core agent infrastructure
"""

import asyncio
import logging
import json
import uuid
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

from framework.agents.base_agent import (
    BaseAgent,
    AgentConfig,
    AgentContext,
    AgentTask,
    AgentResponse,
    TaskStatus,
    LLMProvider,
)

from framework.llms.llm_council import (
    LLMCouncil,
    VotingStrategy,
    PlanProposal,
    CouncilDecision,
    PlanQuality,
    CouncilMember,
)

logger = logging.getLogger(__name__)


class PlanningMode(Enum):
    """Mode of planning operation"""
    DECOMPOSE = "decompose"  # Break down a complex task into steps
    STRATEGIZE = "strategize"  # Develop a strategy/approach
    EVALUATE = "evaluate"  # Evaluate options and recommend best
    OPTIMIZE = "optimize"  # Optimize an existing plan
    REVISE = "revise"  # Revise plan based on feedback


class PlanType(Enum):
    """Type of plan being generated"""
    TASK_EXECUTION = "task_execution"  # Steps to execute a task
    PROBLEM_SOLVING = "problem_solving"  # Approach to solve a problem
    DECISION_MAKING = "decision_making"  # Choosing between options
    IMPLEMENTATION = "implementation"  # Technical implementation plan
    INVESTIGATION = "investigation"  # Research/exploration plan


@dataclass
class PlanStep:
    """Represents a single step in a plan"""
    step_number: int
    action: str
    description: str
    dependencies: List[int] = field(default_factory=list)  # Step numbers this depends on
    estimated_effort: Optional[str] = None  # e.g., "low", "medium", "high"
    required_capabilities: List[str] = field(default_factory=list)
    success_criteria: Optional[str] = None
    fallback_action: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "step_number": self.step_number,
            "action": self.action,
            "description": self.description,
            "dependencies": self.dependencies,
            "estimated_effort": self.estimated_effort,
            "required_capabilities": self.required_capabilities,
            "success_criteria": self.success_criteria,
            "fallback_action": self.fallback_action,
            "metadata": self.metadata,
        }


@dataclass
class ExecutionPlan:
    """Complete execution plan generated by the PlannerAgent"""
    plan_id: str
    goal: str
    plan_type: PlanType
    steps: List[PlanStep]

    # Planning metadata
    planning_mode: PlanningMode
    council_decision: Optional[CouncilDecision] = None
    agreement_score: float = 0.0
    confidence_score: float = 0.0
    quality_assessment: PlanQuality = PlanQuality.ACCEPTABLE

    # Context and reasoning
    reasoning: str = ""
    assumptions: List[str] = field(default_factory=list)
    risks: List[str] = field(default_factory=list)
    success_criteria: List[str] = field(default_factory=list)

    # Alternatives considered
    alternatives: List[str] = field(default_factory=list)
    dissenting_views: List[str] = field(default_factory=list)

    # Retrieved context (from Brain layer)
    retrieved_context: List[Dict[str, Any]] = field(default_factory=list)
    similar_past_tasks: List[Dict[str, Any]] = field(default_factory=list)

    # Timestamps
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "plan_id": self.plan_id,
            "goal": self.goal,
            "plan_type": self.plan_type.value,
            "steps": [step.to_dict() for step in self.steps],
            "planning_mode": self.planning_mode.value,
            "agreement_score": self.agreement_score,
            "confidence_score": self.confidence_score,
            "quality_assessment": self.quality_assessment.value,
            "reasoning": self.reasoning,
            "assumptions": self.assumptions,
            "risks": self.risks,
            "success_criteria": self.success_criteria,
            "alternatives": self.alternatives,
            "dissenting_views": self.dissenting_views,
            "num_retrieved_context": len(self.retrieved_context),
            "num_similar_tasks": len(self.similar_past_tasks),
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat(),
        }


@dataclass
class PlannerConfig:
    """Configuration specific to the PlannerAgent"""
    # Council settings
    enable_council: bool = True
    min_council_members: int = 2
    max_council_members: int = 5
    voting_strategy: VotingStrategy = VotingStrategy.SIMILARITY_CONSENSUS
    min_agreement_threshold: float = 0.5

    # Planning settings
    default_planning_mode: PlanningMode = PlanningMode.DECOMPOSE
    max_plan_steps: int = 20
    include_fallbacks: bool = True
    include_success_criteria: bool = True

    # Context retrieval
    enable_context_retrieval: bool = True
    max_retrieved_context: int = 5
    max_similar_tasks: int = 3

    # Output format
    prefer_structured_output: bool = True
    include_reasoning: bool = True
    include_alternatives: bool = True

    # Quality thresholds
    min_quality_threshold: PlanQuality = PlanQuality.ACCEPTABLE
    retry_on_low_quality: bool = True

    # Caching
    cache_similar_plans: bool = True
    cache_ttl_seconds: int = 3600


class PlannerAgent(BaseAgent):
    """
    High-Level Strategic Planner with Council-of-Experts.

    The PlannerAgent is responsible for:
    1. Breaking down complex tasks into executable steps
    2. Consulting multiple LLMs for diverse perspectives
    3. Synthesizing plans using ensemble decision logic
    4. Retrieving relevant context from the Brain layer
    5. Producing structured, actionable execution plans

    Council of Experts Pattern:
    - Queries multiple LLMs in parallel
    - Compares and evaluates their proposed plans
    - Uses voting strategies (majority, confidence-weighted, LLM-judge)
    - Selects the best plan or synthesizes from multiple

    Usage:
        planner = PlannerAgent(
            agent_name="strategic_planner",
            llm_client=multi_llm_client,
            planner_config=PlannerConfig(voting_strategy=VotingStrategy.LLM_JUDGE),
        )

        task = planner.create_planning_task(
            goal="Implement user authentication with OAuth2",
            planning_mode=PlanningMode.IMPLEMENTATION,
        )

        response = await planner.execute_task(task)
        plan = response.structured_output["plan"]
    """

    def __init__(
        self,
        agent_name: str = "planner_agent",
        agent_type: str = "planner",
        config: Optional[AgentConfig] = None,
        planner_config: Optional[PlannerConfig] = None,
        llm_client=None,
        brain_logger=None,
        security_scanner=None,
        retriever_agent=None,  # Optional RetrieverAgent for context
        default_context: Optional[AgentContext] = None,
    ):
        """
        Initialize the PlannerAgent.

        Args:
            agent_name: Unique name for this planner instance
            agent_type: Type classification (default: "planner")
            config: Base agent configuration
            planner_config: Planner-specific configuration
            llm_client: MultiLLMClient for API calls
            brain_logger: BrainLogger for database logging
            security_scanner: SecurityScanner for PII detection
            retriever_agent: Optional RetrieverAgent for context retrieval
            default_context: Default context with tenant info
        """
        # Initialize base agent
        super().__init__(
            agent_name=agent_name,
            agent_type=agent_type,
            config=config,
            llm_client=llm_client,
            brain_logger=brain_logger,
            security_scanner=security_scanner,
            default_context=default_context,
        )

        self.planner_config = planner_config or PlannerConfig()
        self.retriever_agent = retriever_agent

        # Initialize the LLM council
        self.council = LLMCouncil(
            llm_client=llm_client,
            default_strategy=self.planner_config.voting_strategy,
            min_agreement_threshold=self.planner_config.min_agreement_threshold,
            enable_judge=True,
        )

        # Add default council members based on available providers
        self._initialize_council_members()

        # Plan cache for similar tasks
        self._plan_cache: Dict[str, ExecutionPlan] = {}

        # Planning statistics
        self.planning_stats = {
            "total_plans": 0,
            "successful_plans": 0,
            "council_agreements": 0,
            "avg_agreement_score": 0.0,
            "plan_quality_distribution": {q.value: 0 for q in PlanQuality},
        }

        logger.info(f"PlannerAgent '{agent_name}' initialized with {len(self.council.members)} council members")

    def _initialize_council_members(self):
        """Initialize council members based on available providers"""
        if not self.llm_client:
            logger.warning("No LLM client - council members not initialized")
            return

        # Get available providers
        available = self.llm_client.get_available_providers()

        # Add members with appropriate weights
        member_configs = [
            ("anthropic", "claude-3-5-sonnet-20241022", 1.2, "reasoning"),
            ("openai", "gpt-4-turbo-preview", 1.0, "general"),
            ("google", "gemini-pro", 0.9, "analysis"),
        ]

        for provider, model, weight, specialty in member_configs:
            if provider in available:
                self.council.add_member(provider, model, weight, specialty)
                if len(self.council.members) >= self.planner_config.max_council_members:
                    break

    def _initialize_capabilities(self) -> List[str]:
        """Define planner-specific capabilities"""
        return [
            "task-decomposition",
            "strategic-planning",
            "option-evaluation",
            "plan-optimization",
            "plan-revision",
            "multi-llm-consultation",
            "consensus-building",
            "risk-assessment",
            "dependency-analysis",
        ]

    def _get_system_prompt(self, task: AgentTask) -> str:
        """Generate system prompt based on planning mode"""
        mode = task.parameters.get("planning_mode", PlanningMode.DECOMPOSE.value)
        plan_type = task.parameters.get("plan_type", PlanType.TASK_EXECUTION.value)

        base_prompt = """You are an expert strategic planner and task decomposition specialist.
Your role is to analyze complex goals and create detailed, actionable execution plans.

When creating plans, you should:
1. Break down the goal into clear, specific steps
2. Consider dependencies between steps
3. Identify potential risks and mitigation strategies
4. Suggest success criteria for each step
5. Consider alternative approaches when appropriate

Format your response as a structured plan with numbered steps.
Each step should include:
- A clear action to take
- A brief description of what this accomplishes
- Any dependencies on previous steps
- Success criteria (how to know the step is complete)
"""

        mode_specific = {
            PlanningMode.DECOMPOSE.value: """
Focus on breaking down the task into atomic, executable steps.
Ensure each step is small enough to be completed without further decomposition.
Order steps logically, respecting dependencies.
""",
            PlanningMode.STRATEGIZE.value: """
Focus on developing a high-level strategy.
Consider multiple approaches and recommend the best one.
Explain the reasoning behind your strategic choices.
Identify key decision points and alternatives.
""",
            PlanningMode.EVALUATE.value: """
Focus on evaluating the options presented.
Analyze pros and cons of each option.
Provide a clear recommendation with justification.
Consider both short-term and long-term implications.
""",
            PlanningMode.OPTIMIZE.value: """
Focus on improving the existing plan.
Identify inefficiencies or potential issues.
Suggest optimizations while maintaining the core approach.
Ensure changes don't introduce new risks.
""",
            PlanningMode.REVISE.value: """
Focus on revising the plan based on the feedback provided.
Address the specific issues raised.
Maintain consistency with successful parts of the original plan.
Explain what changes were made and why.
""",
        }

        plan_type_context = {
            PlanType.TASK_EXECUTION.value: "Create an execution plan with concrete action items.",
            PlanType.PROBLEM_SOLVING.value: "Create a problem-solving approach with analysis steps.",
            PlanType.DECISION_MAKING.value: "Create a decision framework with evaluation criteria.",
            PlanType.IMPLEMENTATION.value: "Create a technical implementation plan with detailed steps.",
            PlanType.INVESTIGATION.value: "Create a research/investigation plan with discovery phases.",
        }

        prompt = base_prompt + mode_specific.get(mode, "") + "\n" + plan_type_context.get(plan_type, "")

        # Add retrieved context if available
        if task.context and self.planner_config.include_reasoning:
            prompt += f"\n\nRelevant Context:\n{task.context}"

        return prompt

    def _process_response(
        self,
        raw_response: str,
        task: AgentTask,
    ) -> Dict[str, Any]:
        """Process the LLM response and extract structured plan"""
        # Try to extract structured plan
        steps = self._extract_plan_steps(raw_response)
        reasoning = self._extract_reasoning(raw_response)
        risks = self._extract_risks(raw_response)
        assumptions = self._extract_assumptions(raw_response)

        # Build execution plan
        plan = ExecutionPlan(
            plan_id=f"plan_{uuid.uuid4().hex[:12]}",
            goal=task.description or task.prompt[:100],
            plan_type=PlanType(task.parameters.get("plan_type", PlanType.TASK_EXECUTION.value)),
            steps=steps,
            planning_mode=PlanningMode(task.parameters.get("planning_mode", PlanningMode.DECOMPOSE.value)),
            reasoning=reasoning,
            risks=risks,
            assumptions=assumptions,
            confidence_score=self._calculate_plan_confidence(steps, raw_response),
        )

        return {
            "text": raw_response,
            "structured_output": {
                "plan": plan.to_dict(),
                "raw_steps": [s.to_dict() for s in steps],
            },
        }

    def _fallback_handler(self, task: AgentTask, error: str) -> AgentResponse:
        """Handle cases when all LLM calls fail"""
        logger.warning(f"All LLM calls failed for planning task: {error}")

        # Create a minimal fallback plan
        fallback_steps = [
            PlanStep(
                step_number=1,
                action="Review task requirements",
                description="Manually review the task requirements and constraints",
            ),
            PlanStep(
                step_number=2,
                action="Break down into subtasks",
                description="Identify and list the main subtasks required",
            ),
            PlanStep(
                step_number=3,
                action="Execute subtasks sequentially",
                description="Complete each subtask in order",
                dependencies=[1, 2],
            ),
        ]

        fallback_plan = ExecutionPlan(
            plan_id=f"fallback_{uuid.uuid4().hex[:8]}",
            goal=task.description or task.prompt[:100],
            plan_type=PlanType.TASK_EXECUTION,
            steps=fallback_steps,
            planning_mode=PlanningMode.DECOMPOSE,
            reasoning="Fallback plan generated due to LLM failures",
            quality_assessment=PlanQuality.POOR,
            confidence_score=0.3,
        )

        return AgentResponse(
            task_id=task.task_id,
            success=False,
            status=TaskStatus.FAILED,
            response_text="Planning failed - using fallback plan",
            structured_output={"plan": fallback_plan.to_dict()},
            error=error,
            error_type="PlanningFailure",
        )

    async def execute_task(self, task: AgentTask) -> AgentResponse:
        """
        Execute a planning task, optionally using the council of experts.

        This overrides the base execute_task to add council consultation
        for planning tasks when enabled.
        """
        # Check if council mode is enabled and we have enough members
        use_council = (
            self.planner_config.enable_council and
            len(self.council.members) >= self.planner_config.min_council_members and
            task.parameters.get("use_council", True)
        )

        if use_council:
            return await self._execute_with_council(task)
        else:
            # Use standard single-LLM execution
            return await super().execute_task(task)

    async def _execute_with_council(self, task: AgentTask) -> AgentResponse:
        """Execute planning task using the council of experts"""
        import time
        start_time = time.time()
        run_id: Optional[str] = None

        # Merge context
        if task.agent_context is None and self.default_context:
            task.agent_context = self.default_context

        tenant_id = task.agent_context.tenant_id if task.agent_context else None

        # Start Brain logging
        if self._brain_logger and self.config.enable_brain_logging:
            try:
                run_id = self._brain_logger.start_run(
                    agent_id=self.agent_id,
                    agent_name=self.agent_name,
                    agent_type=self.agent_type,
                    tenant_id=tenant_id,
                    task_id=task.task_id,
                    input_data={
                        "prompt": task.prompt[:500],
                        "task_type": task.task_type,
                        "planning_mode": task.parameters.get("planning_mode"),
                        "use_council": True,
                    },
                    context=task.agent_context.to_dict() if task.agent_context else {},
                )
            except Exception as e:
                logger.warning(f"Failed to start Brain logging: {e}")

        self._log_event("council_planning_started", {
            "task_id": task.task_id,
            "num_council_members": len(self.council.members),
            "voting_strategy": self.planner_config.voting_strategy.value,
        }, run_id)

        try:
            # Step 1: Retrieve relevant context (if enabled)
            retrieved_context = []
            similar_tasks = []

            if self.planner_config.enable_context_retrieval and self.retriever_agent:
                retrieved_context, similar_tasks = await self._retrieve_planning_context(
                    task, tenant_id
                )
                self._log_event("context_retrieved", {
                    "num_context": len(retrieved_context),
                    "num_similar_tasks": len(similar_tasks),
                }, run_id)

            # Step 2: Build the planning prompt
            planning_prompt = self._build_planning_prompt(task, retrieved_context, similar_tasks)
            system_prompt = self._get_system_prompt(task)

            # Step 3: Query the council
            proposals = await self.council.query_all(
                prompt=planning_prompt,
                system_prompt=system_prompt,
                temperature=task.parameters.get("temperature", 0.7),
                max_tokens=task.parameters.get("max_tokens", 4096),
            )

            if not proposals:
                raise RuntimeError("No proposals received from council")

            self._log_event("council_proposals_received", {
                "num_proposals": len(proposals),
                "providers": [p.member.provider for p in proposals],
            }, run_id)

            # Step 4: Evaluate responses and select best plan
            decision = await self.council.evaluate_responses(
                proposals,
                strategy=self.planner_config.voting_strategy,
                task_context=task.description,
            )

            # Step 5: Build the final execution plan
            execution_plan = self._build_execution_plan(
                task=task,
                decision=decision,
                retrieved_context=retrieved_context,
                similar_tasks=similar_tasks,
            )

            # Update statistics
            self._update_planning_stats(execution_plan, decision)

            # Check quality threshold
            if (
                execution_plan.quality_assessment.value < self.planner_config.min_quality_threshold.value and
                self.planner_config.retry_on_low_quality
            ):
                self._log_event("low_quality_plan", {
                    "quality": execution_plan.quality_assessment.value,
                    "threshold": self.planner_config.min_quality_threshold.value,
                }, run_id)

            processing_time = time.time() - start_time

            response = AgentResponse(
                task_id=task.task_id,
                success=True,
                status=TaskStatus.COMPLETED,
                response_text=decision.winning_proposal.raw_response,
                structured_output={
                    "plan": execution_plan.to_dict(),
                    "council_decision": decision.to_dict(),
                    "steps": [s.to_dict() for s in execution_plan.steps],
                },
                llm_provider=LLMProvider(decision.winning_proposal.member.provider.upper()) if hasattr(LLMProvider, decision.winning_proposal.member.provider.upper()) else None,
                model_used=decision.winning_proposal.member.model,
                confidence_score=execution_plan.confidence_score,
                processing_time_seconds=processing_time,
                run_id=run_id,
            )

            self._log_event("council_planning_completed", {
                "task_id": task.task_id,
                "winner": decision.winning_proposal.member.provider,
                "agreement_score": decision.agreement_score,
                "num_steps": len(execution_plan.steps),
                "quality": execution_plan.quality_assessment.value,
            }, run_id)

            # Complete Brain logging
            if self._brain_logger and run_id:
                self._brain_logger.complete_run(
                    run_id=run_id,
                    success=True,
                    output_data={
                        "plan_id": execution_plan.plan_id,
                        "num_steps": len(execution_plan.steps),
                        "agreement_score": decision.agreement_score,
                        "quality": execution_plan.quality_assessment.value,
                    },
                    model_used=decision.winning_proposal.member.model,
                )

            return response

        except Exception as e:
            logger.error(f"Council planning failed: {e}")

            if self._brain_logger and run_id:
                self._brain_logger.fail_run(
                    run_id=run_id,
                    error=str(e),
                    error_type="CouncilPlanningError",
                )

            return self._fallback_handler(task, str(e))

    async def _retrieve_planning_context(
        self,
        task: AgentTask,
        tenant_id: Optional[str],
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Retrieve relevant context from Brain layer for planning"""
        retrieved_context = []
        similar_tasks = []

        if not self.retriever_agent:
            return retrieved_context, similar_tasks

        try:
            # Retrieve relevant knowledge
            retrieval_task = self.retriever_agent.create_task(
                prompt=task.description or task.prompt[:500],
                task_type="retrieval",
                description="Retrieve context for planning",
                tenant_id=tenant_id,
                parameters={
                    "top_k": self.planner_config.max_retrieved_context,
                    "include_similar_tasks": True,
                    "max_similar_tasks": self.planner_config.max_similar_tasks,
                },
            )

            retrieval_response = await self.retriever_agent.execute_task(retrieval_task)

            if retrieval_response.success and retrieval_response.structured_output:
                retrieved_context = retrieval_response.structured_output.get("context", [])
                similar_tasks = retrieval_response.structured_output.get("similar_tasks", [])

        except Exception as e:
            logger.warning(f"Context retrieval failed: {e}")

        return retrieved_context, similar_tasks

    def _build_planning_prompt(
        self,
        task: AgentTask,
        retrieved_context: List[Dict[str, Any]],
        similar_tasks: List[Dict[str, Any]],
    ) -> str:
        """Build the planning prompt with context"""
        prompt_parts = [
            "# Planning Task",
            "",
            f"**Goal:** {task.description or task.prompt}",
            "",
        ]

        # Add parameters context
        if task.parameters:
            mode = task.parameters.get("planning_mode", "decompose")
            plan_type = task.parameters.get("plan_type", "task_execution")
            prompt_parts.extend([
                f"**Planning Mode:** {mode}",
                f"**Plan Type:** {plan_type}",
                "",
            ])

        # Add constraints if provided
        constraints = task.parameters.get("constraints", [])
        if constraints:
            prompt_parts.extend([
                "## Constraints",
                "",
            ])
            for constraint in constraints:
                prompt_parts.append(f"- {constraint}")
            prompt_parts.append("")

        # Add retrieved context
        if retrieved_context:
            prompt_parts.extend([
                "## Relevant Knowledge",
                "",
            ])
            for ctx in retrieved_context[:5]:
                content = ctx.get("content", ctx.get("text", ""))[:300]
                prompt_parts.append(f"- {content}")
            prompt_parts.append("")

        # Add similar past tasks
        if similar_tasks:
            prompt_parts.extend([
                "## Similar Past Tasks",
                "",
            ])
            for task_info in similar_tasks[:3]:
                desc = task_info.get("description", "")[:200]
                outcome = task_info.get("outcome", "")[:100]
                prompt_parts.append(f"- Task: {desc}")
                if outcome:
                    prompt_parts.append(f"  Outcome: {outcome}")
            prompt_parts.append("")

        # Add output format instructions
        prompt_parts.extend([
            "## Required Output Format",
            "",
            "Please provide a structured plan with the following:",
            "1. Numbered steps (1., 2., 3., etc.)",
            "2. Clear action and description for each step",
            "3. Dependencies between steps (if any)",
            "4. Potential risks or considerations",
            "5. Success criteria for the overall plan",
            "",
            "Begin your plan:",
        ])

        return "\n".join(prompt_parts)

    def _build_execution_plan(
        self,
        task: AgentTask,
        decision: CouncilDecision,
        retrieved_context: List[Dict[str, Any]],
        similar_tasks: List[Dict[str, Any]],
    ) -> ExecutionPlan:
        """Build the final execution plan from council decision"""
        winning_proposal = decision.winning_proposal

        # Extract steps from the winning proposal
        steps = self._extract_plan_steps(winning_proposal.raw_response)

        # If no steps extracted, create from consensus steps
        if not steps and decision.consensus_steps:
            steps = [
                PlanStep(
                    step_number=i + 1,
                    action=step.split(':')[0] if ':' in step else step,
                    description=step.split(':', 1)[1].strip() if ':' in step else step,
                )
                for i, step in enumerate(decision.consensus_steps)
            ]

        # Extract additional elements
        reasoning = self._extract_reasoning(winning_proposal.raw_response)
        risks = self._extract_risks(winning_proposal.raw_response) + winning_proposal.risks
        assumptions = self._extract_assumptions(winning_proposal.raw_response)

        plan = ExecutionPlan(
            plan_id=f"plan_{uuid.uuid4().hex[:12]}",
            goal=task.description or task.prompt[:100],
            plan_type=PlanType(task.parameters.get("plan_type", PlanType.TASK_EXECUTION.value)),
            steps=steps,
            planning_mode=PlanningMode(task.parameters.get("planning_mode", PlanningMode.DECOMPOSE.value)),
            council_decision=decision,
            agreement_score=decision.agreement_score,
            confidence_score=decision.confidence_score,
            quality_assessment=decision.quality_assessment,
            reasoning=reasoning or decision.deliberation_summary,
            assumptions=assumptions,
            risks=list(set(risks)),
            success_criteria=self._extract_success_criteria(winning_proposal.raw_response),
            alternatives=[
                f"[{p.member.provider}] {p.steps[0] if p.steps else 'N/A'}"
                for p in decision.all_proposals if p is not winning_proposal
            ][:3],
            dissenting_views=decision.dissenting_views,
            retrieved_context=retrieved_context,
            similar_past_tasks=similar_tasks,
        )

        return plan

    def _extract_plan_steps(self, text: str) -> List[PlanStep]:
        """Extract structured plan steps from response text"""
        import re

        steps = []
        step_patterns = [
            r'^\s*(\d+)[\.\)]\s*\**([^:*]+)\**[:\s]*(.*)$',  # "1. Step: description" or "1) **Step**: description"
            r'^\s*Step\s+(\d+)[:\s]+\**([^:*]+)\**[:\s]*(.*)$',  # "Step 1: Step name: description"
            r'^\s*[-*]\s*\**([^:*]+)\**[:\s]+(.*)$',  # "- **Step**: description"
        ]

        lines = text.split('\n')
        current_step_num = 0

        for line in lines:
            line = line.strip()
            if not line:
                continue

            for pattern in step_patterns:
                match = re.match(pattern, line, re.IGNORECASE)
                if match:
                    groups = match.groups()

                    if len(groups) == 3:  # Pattern with number
                        step_num = int(groups[0])
                        action = groups[1].strip()
                        description = groups[2].strip()
                    elif len(groups) == 2:  # Pattern without number
                        current_step_num += 1
                        step_num = current_step_num
                        action = groups[0].strip()
                        description = groups[1].strip()
                    else:
                        continue

                    # Skip empty or very short steps
                    if len(action) < 3:
                        continue

                    step = PlanStep(
                        step_number=step_num,
                        action=action[:200],
                        description=description[:500] if description else action,
                    )
                    steps.append(step)
                    break

        # If no steps found, try simpler extraction
        if not steps:
            simple_pattern = r'^\s*\d+[\.\)]\s*(.+)$'
            for i, line in enumerate(lines):
                match = re.match(simple_pattern, line.strip())
                if match:
                    content = match.group(1).strip()
                    if len(content) > 5:
                        steps.append(PlanStep(
                            step_number=len(steps) + 1,
                            action=content[:200],
                            description=content,
                        ))

        return steps[:self.planner_config.max_plan_steps]

    def _extract_reasoning(self, text: str) -> str:
        """Extract reasoning/rationale from response"""
        import re

        patterns = [
            r'(?:reasoning|rationale|approach|strategy)[:\s]+(.+?)(?=\n\n|\Z)',
            r'(?:this approach|the plan|we will)[:\s]*(.+?)(?=\n\n|\Z)',
        ]

        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                return match.group(1).strip()[:500]

        return ""

    def _extract_risks(self, text: str) -> List[str]:
        """Extract risks from response"""
        import re

        risks = []
        patterns = [
            r'(?:risk|caveat|warning|consideration|potential issue)[:\s]+([^.]+\.)',
            r'(?:be aware|note that|keep in mind)[:\s]+([^.]+\.)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            risks.extend(matches)

        return list(set(risks))[:5]

    def _extract_assumptions(self, text: str) -> List[str]:
        """Extract assumptions from response"""
        import re

        assumptions = []
        patterns = [
            r'(?:assum(?:e|ing|ption))[:\s]+([^.]+\.)',
            r'(?:prerequisite|requirement)[:\s]+([^.]+\.)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            assumptions.extend(matches)

        return list(set(assumptions))[:5]

    def _extract_success_criteria(self, text: str) -> List[str]:
        """Extract success criteria from response"""
        import re

        criteria = []
        patterns = [
            r'(?:success criteria|completion criteria|done when)[:\s]+([^.]+\.)',
            r'(?:successful|complete|finished) (?:when|if)[:\s]+([^.]+\.)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            criteria.extend(matches)

        return list(set(criteria))[:5]

    def _calculate_plan_confidence(self, steps: List[PlanStep], raw_response: str) -> float:
        """Calculate confidence score for a plan"""
        score = 0.5

        # Boost for having steps
        if len(steps) >= 3:
            score += 0.15
        elif len(steps) >= 1:
            score += 0.05

        # Check for structured elements
        if any('success' in s.description.lower() for s in steps if s.description):
            score += 0.1

        if any(s.dependencies for s in steps):
            score += 0.1

        # Check response quality indicators
        quality_indicators = ['therefore', 'because', 'ensures', 'achieves']
        text_lower = raw_response.lower()
        for indicator in quality_indicators:
            if indicator in text_lower:
                score += 0.03

        return min(1.0, max(0.0, score))

    def _update_planning_stats(self, plan: ExecutionPlan, decision: CouncilDecision):
        """Update planning statistics"""
        self.planning_stats["total_plans"] += 1

        if plan.confidence_score >= 0.7:
            self.planning_stats["successful_plans"] += 1

        if decision.agreement_score >= self.planner_config.min_agreement_threshold:
            self.planning_stats["council_agreements"] += 1

        # Update average agreement
        n = self.planning_stats["total_plans"]
        old_avg = self.planning_stats["avg_agreement_score"]
        self.planning_stats["avg_agreement_score"] = (old_avg * (n-1) + decision.agreement_score) / n

        # Update quality distribution
        self.planning_stats["plan_quality_distribution"][plan.quality_assessment.value] += 1

    def create_planning_task(
        self,
        goal: str,
        planning_mode: PlanningMode = PlanningMode.DECOMPOSE,
        plan_type: PlanType = PlanType.TASK_EXECUTION,
        constraints: Optional[List[str]] = None,
        context: Optional[str] = None,
        use_council: bool = True,
        tenant_id: Optional[str] = None,
        **kwargs
    ) -> AgentTask:
        """
        Create a planning task with appropriate parameters.

        Args:
            goal: The goal or task to plan for
            planning_mode: How to approach the planning
            plan_type: Type of plan to generate
            constraints: Optional constraints to consider
            context: Optional additional context
            use_council: Whether to use council of experts
            tenant_id: Tenant ID for isolation
            **kwargs: Additional task parameters

        Returns:
            Configured AgentTask for planning
        """
        return self.create_task(
            prompt=goal,
            task_type="planning",
            description=goal[:200],
            tenant_id=tenant_id,
            context=context,
            parameters={
                "planning_mode": planning_mode.value,
                "plan_type": plan_type.value,
                "constraints": constraints or [],
                "use_council": use_council,
                **kwargs,
            },
        )

    async def revise_plan(
        self,
        original_plan: ExecutionPlan,
        feedback: str,
        failed_step: Optional[int] = None,
        tenant_id: Optional[str] = None,
    ) -> AgentResponse:
        """
        Revise an existing plan based on feedback.

        Args:
            original_plan: The plan to revise
            feedback: Feedback about what went wrong or needs changing
            failed_step: Optional step number that failed
            tenant_id: Tenant ID for isolation

        Returns:
            AgentResponse with revised plan
        """
        revision_prompt = f"""# Plan Revision Request

## Original Goal
{original_plan.goal}

## Original Plan
"""
        for step in original_plan.steps:
            status = "[FAILED]" if failed_step and step.step_number == failed_step else ""
            revision_prompt += f"\n{step.step_number}. {step.action} {status}"
            revision_prompt += f"\n   {step.description}"

        revision_prompt += f"""

## Feedback
{feedback}

## Instructions
Please revise the plan to address the feedback.
Maintain successful parts of the original plan where possible.
Clearly explain any changes made.
"""

        task = self.create_planning_task(
            goal=revision_prompt,
            planning_mode=PlanningMode.REVISE,
            plan_type=original_plan.plan_type,
            tenant_id=tenant_id,
            parameters={
                "original_plan_id": original_plan.plan_id,
                "failed_step": failed_step,
            },
        )

        return await self.execute_task(task)

    def get_planning_stats(self) -> Dict[str, Any]:
        """Get planning statistics"""
        return {
            **self.planning_stats,
            "council_stats": self.council.get_member_stats(),
            "num_council_members": len(self.council.members),
        }

    def get_capabilities(self) -> Dict[str, Any]:
        """Get agent capabilities including planner-specific info"""
        base_capabilities = super().get_capabilities()
        base_capabilities.update({
            "planner_config": {
                "enable_council": self.planner_config.enable_council,
                "voting_strategy": self.planner_config.voting_strategy.value,
                "min_council_members": self.planner_config.min_council_members,
                "enable_context_retrieval": self.planner_config.enable_context_retrieval,
            },
            "planning_stats": self.get_planning_stats(),
            "council_members": [m.to_dict() for m in self.council.members],
        })
        return base_capabilities


# Convenience factory function
def create_planner_agent(
    llm_client,
    brain_logger=None,
    retriever_agent=None,
    voting_strategy: VotingStrategy = VotingStrategy.SIMILARITY_CONSENSUS,
    enable_council: bool = True,
    tenant_id: Optional[str] = None,
) -> PlannerAgent:
    """
    Create a configured PlannerAgent.

    Args:
        llm_client: MultiLLMClient instance
        brain_logger: Optional BrainLogger instance
        retriever_agent: Optional RetrieverAgent for context
        voting_strategy: Council voting strategy
        enable_council: Whether to enable council of experts
        tenant_id: Default tenant ID

    Returns:
        Configured PlannerAgent instance
    """
    config = AgentConfig(
        enable_brain_logging=brain_logger is not None,
    )

    planner_config = PlannerConfig(
        enable_council=enable_council,
        voting_strategy=voting_strategy,
    )

    default_context = None
    if tenant_id:
        default_context = AgentContext(tenant_id=tenant_id)

    return PlannerAgent(
        agent_name="strategic_planner",
        config=config,
        planner_config=planner_config,
        llm_client=llm_client,
        brain_logger=brain_logger,
        retriever_agent=retriever_agent,
        default_context=default_context,
    )
